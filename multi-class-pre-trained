import os
import matplotlib
import numpy as np
import pandas as pd
import tensorflow as tf
import matplotlib.image as mpimg
from sklearn import preprocessing

from google.colab import drive
drive.mount('/content/gdrive')


import tensorflow as tf

import os
import numpy as np
from PIL import Image
import numpy as np

from tensorflow.keras import models, layers
from tensorflow.keras.models import Sequential
from tensorflow.keras.optimizers import SGD
from tensorflow.keras.layers import Dense, Activation, Dropout, Flatten
from tensorflow.keras.layers import Conv2D, MaxPooling2D


from tensorflow.keras.applications import ResNet50
from tensorflow.keras.applications import VGG16
from tensorflow.keras.applications import InceptionV3


import matplotlib.pyplot as plt
import pandas as pd
import numpy as np
import cv2
import os

from glob import glob


#pretrained models
def vgg_model():
 
  conv_base_vgg16 = VGG16(weights = 'imagenet', include_top = False, input_shape = (32,32,3))  
  
  print('Number of trainable weights before freezing the conv base:', len(conv_base_vgg16.trainable_weights))
  conv_base_vgg16.trainable = False
  print('Number of trainable weights after freezing the conv base:', len(conv_base_vgg16.trainable_weights))
  vgg16_model = Sequential()
  vgg16_model.add(conv_base_vgg16)
  vgg16_model.add(Flatten())
  vgg16_model.add(Dense(512, activation='relu'))
  vgg16_model.add(Dense(256, activation='relu'))
  vgg16_model.add(Dense(10, activation='softmax'))
  vgg16_model.summary()
  
  return vgg16_model


def ResNet50_model():
 
  conv_base_ResNet50 = ResNet50(weights = 'imagenet', include_top = False, input_shape = (32,32,3))
  
  print('Number of trainable weights before freezing the conv base:', len(conv_base_ResNet50.trainable_weights))
  conv_base_ResNet50.trainable = False
  print('Number of trainable weights after freezing the conv base:', len(conv_base_ResNet50.trainable_weights))
  
  ResNet50_model = Sequential()
  ResNet50_model.add(conv_base_ResNet50)
  ResNet50_model.add(Flatten())
  ResNet50_model.add(Dense(512, activation='relu'))
  ResNet50_model.add(Dense(256, activation='relu'))
  ResNet50_model.add(Dense(10, activation='softmax'))
  ResNet50_model.summary()
  
  return ResNet50_model


def InceptionV3_model():
  
  conv_base_InceptionV3 = InceptionV3(weights = 'imagenet', include_top = False, input_shape = (32,32,3)) 
  
  print('Number of trainable weights before freezing the conv base:', len(conv_base_InceptionV3.trainable_weights))
  conv_base_InceptionV3.trainable = False
  print('Number of trainable weights after freezing the conv base:', len(conv_base_InceptionV3.trainable_weights))

  InceptionV3_model = Sequential()
  InceptionV3_model.add(conv_base_InceptionV3)
  InceptionV3_model.add(Flatten())
  InceptionV3_model.add(Dense(512, activation='relu'))
  InceptionV3_model.add(Dense(256, activation='relu'))
  InceptionV3_model.add(Dense(10, activation='softmax'))
  InceptionV3_model.summary()
  
  return InceptionV3_model



def main():

  ((trainX, trainY), (testX, testY)) = tf.keras.datasets.cifar10.load_data()
  print('shape of input:', trainX.shape)
  
  NUM_EPOCHS = 20
  trainX = trainX.astype("uint8")/ 255.0
  testX = testX.astype("uint8")/ 255.0
    
  print("Compiling model...")
  opt = tf.keras.optimizers.SGD(lr=0.01)
  model1 = vgg_model()
  model2 = ResNet50_model()
  model3 = InceptionV3_model()
 
  model1.compile(loss="sparse_categorical_crossentropy", optimizer=opt, metrics=["accuracy"])
  model2.compile(loss="sparse_categorical_crossentropy", optimizer=opt, metrics=["accuracy"])
  model3.compile(loss="sparse_categorical_crossentropy", optimizer=opt, metrics=["accuracy"])
  
  #print (model1.summary())

    
  print("Training network ModelM1..... ", )
  H1 = model1.fit(trainX, trainY, validation_data=(testX, testY),
                  batch_size=64, epochs=NUM_EPOCHS, validation_split=0.2)
    
  plt.style.use("ggplot")
  plt.figure()
  plt.plot(np.arange(0, NUM_EPOCHS), H1.history["loss"], label="train_loss")
  plt.plot(np.arange(0, NUM_EPOCHS), H1.history["val_loss"], label="val_loss")
  plt.plot(np.arange(0, NUM_EPOCHS), H1.history["acc"], label="train_acc")
  plt.plot(np.arange(0, NUM_EPOCHS), H1.history["val_acc"], label="val_acc")
  plt.title("Training Loss and Accuracy")
  plt.xlabel("Epoch #")
  plt.ylabel("Loss/Accuracy")
  plt.legend()
  plt.show()
  
  print("Training network ModelM2.....")
  H2 = model2.fit(trainX, trainY, validation_data=(testX, testY),
                  batch_size=64, epochs=NUM_EPOCHS, validation_split=0.2)
  
    
  plt.style.use("ggplot")
  plt.figure()
  plt.plot(np.arange(0, NUM_EPOCHS), H2.history["loss"], label="train_loss")
  plt.plot(np.arange(0, NUM_EPOCHS), H2.history["val_loss"], label="val_loss")
  plt.plot(np.arange(0, NUM_EPOCHS), H2.history["acc"], label="train_acc")
  plt.plot(np.arange(0, NUM_EPOCHS), H2.history["val_acc"], label="val_acc")
  plt.title("Training Loss and Accuracy")
  plt.xlabel("Epoch #")
  plt.ylabel("Loss/Accuracy")
  plt.legend()
  plt.show()
  
  print("Training network ModelM3.....")
  H3 = model3.fit(trainX, trainY, validation_data=(testX, testY),
                  batch_size=64, epochs=NUM_EPOCHS, validation_split=0.2)
    
  plt.style.use("ggplot")
  plt.figure()
  plt.plot(np.arange(0, NUM_EPOCHS), H3.history["loss"], label="train_loss")
  plt.plot(np.arange(0, NUM_EPOCHS), H3.history["val_loss"], label="val_loss")
  plt.plot(np.arange(0, NUM_EPOCHS), H3.history["acc"], label="train_acc")
  plt.plot(np.arange(0, NUM_EPOCHS), H3.history["val_acc"], label="val_acc")
  plt.title("Training Loss and Accuracy")
  plt.xlabel("Epoch #")
  plt.ylabel("Loss/Accuracy")
  plt.legend()
  plt.show()
  
  
  
  
  
  
  
  
main()

