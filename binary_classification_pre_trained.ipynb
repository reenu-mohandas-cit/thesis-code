{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "binary_classification_pre-trained.ipynb",
      "version": "0.3.2",
      "provenance": [],
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/reenu-mohandas-cit/thesis-code/blob/master/binary_classification_pre_trained.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "92JA65cxVMQT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import cv2\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline \n",
        "\n",
        "\n",
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "path =  '/content/gdrive/My Drive/keras_lab_dataset/dogs_cats/dogs_cats/data'\n",
        "\n",
        "\n",
        "from keras.applications import InceptionResNetV2\n",
        "\n",
        "conv_base = InceptionResNetV2(weights = 'imagenet', include_top = False, input_shape = (64,64,3))\n",
        "\n",
        "from keras.applications import VGG16\n",
        "\n",
        "conv_base_vgg16 = VGG16(weights = 'imagenet', include_top = False, input_shape = (64,64,3))\n",
        "\n",
        "from keras.applications import ResNet50\n",
        "\n",
        "conv_base_ResNet50 = ResNet50(weights = 'imagenet', include_top = False, input_shape = (64,64,3))\n",
        "\n",
        "from keras.applications import InceptionV3\n",
        "\n",
        "conv_base_InceptionV3 = InceptionV3(weights = 'imagenet', include_top = False, input_shape = (64,64,3))\n",
        "\n",
        "\n",
        "def preprocess_dataset(dataDir, labelDictionary):\n",
        "  x = []\n",
        "  y = []\n",
        "  \n",
        "  \n",
        "  width, height = 64, 64\n",
        "  \n",
        "  # list folders in directory \n",
        "  directory = os.listdir(dataDir)\n",
        "  \n",
        "  #for each folder (train and validation)\n",
        "  for label in directory:\n",
        "    \n",
        "    #add class label to label dictionary\n",
        "    if label not in labelDictionary:\n",
        "      labelDictionary[label] = len(labelDictionary)\n",
        "      \n",
        "    # create full path for image directory \n",
        "    #(append absolute and image directory path)\n",
        "    sourceImages = os.path.join(dataDir, label)\n",
        "    images = os.listdir(sourceImages)\n",
        "    \n",
        "    #for each image in directory\n",
        "    for image in images:\n",
        "      \n",
        "      #read the image from file, resize and add to a list\n",
        "      full_size_image = cv2.imread(os.path.join(sourceImages, image))\n",
        "      x.append(cv2.resize(full_size_image, (width, height), \n",
        "                         interpolation = cv2.INTER_CUBIC))\n",
        "      \n",
        "      #add the class label to y\n",
        "      y.append(label)\n",
        "      \n",
        "  return np.array(x), np.array(y)\n",
        "\n",
        "\n",
        "\n",
        "def read_and_process_image(list_of_images):\n",
        "\n",
        "  #   initialise the array for image\n",
        "    X = []\n",
        "  #   initialise the array for label\n",
        "    y = [] \n",
        "    \n",
        "    for image in list_of_images:\n",
        "        X.append(cv2.resize(cv2.imread(image, cv2.IMREAD_COLOR), (nrows,ncolumns), interpolation=cv2.INTER_CUBIC)) \n",
        "      \n",
        "        if 'dog' in image:\n",
        "            y.append(1)\n",
        "        elif 'cat' in image:\n",
        "            y.append(0)\n",
        "    \n",
        "    return X, y\n",
        "\n",
        "X, y = read_and_process_image(train_imgs)\n",
        "X = np.array(X)\n",
        "y = np.array(y)\n",
        "\n",
        "\n",
        "ntrain = len(X_train)\n",
        "nval = len(X_val)\n",
        "batch_size = 32\n",
        "\n",
        "from sklearn.model_selection import train_test_split\n",
        "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.20, random_state=2)\n",
        "\n",
        "print(\"Shape of train images is:\", X_train.shape)\n",
        "print(\"Shape of validation images is:\", X_val.shape)\n",
        "print(\"Shape of labels is:\", y_train.shape)\n",
        "print(\"Shape of labels is:\", y_val.shape)\n",
        "\n",
        "\n",
        "\n",
        "from keras import layers\n",
        "from keras import models\n",
        "from keras import optimizers\n",
        "from keras.preprocessing.image import ImageDataGenerator\n",
        "from keras.preprocessing.image import img_to_array, load_img\n",
        "\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(conv_base)\n",
        "model.add(layers.Flatten())\n",
        "model.add(layers.Dense(256, activation='relu'))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "model.summary()\n",
        "\n",
        "\n",
        "model.compile(loss='binary_crossentropy', optimizer=optimizers.RMSprop(lr=2e-5), metrics=['acc'])\n",
        "\n",
        "\n",
        "\n",
        "# Data Augmentation step where image processing techniques like rotation_range, \n",
        "# width_shift_range, height_shift_range, shear_range, zoom_range, \n",
        "# horizontal_flip are applied on all the image instances, to generate new\n",
        "# image instances to provide sufficiently large dataset for model training\n",
        "\n",
        "train_datagen = ImageDataGenerator(rescale=1./255,  \n",
        "                                    rotation_range=40,\n",
        "                                    width_shift_range=0.2,\n",
        "                                    height_shift_range=0.2,\n",
        "                                    shear_range=0.2,\n",
        "                                    zoom_range=0.2,\n",
        "                                    horizontal_flip=True,)\n",
        "\n",
        "val_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "\n",
        "train_generator = train_datagen.flow(X_train, y_train, batch_size=batch_size)\n",
        "val_generator = val_datagen.flow(X_val, y_val, batch_size=batch_size)\n",
        "\n",
        "\n",
        "H = model.fit_generator(train_generator,\n",
        "                              steps_per_epoch=ntrain // batch_size,\n",
        "                              epochs=20,\n",
        "                              validation_data=val_generator,\n",
        "                              validation_steps=nval // batch_size)\n",
        "\n",
        "# store the history of training in history and its plot the graphs\n",
        "\n",
        "import tensorflow as tf\n",
        "import h5py\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "from glob import glob\n",
        "NUM_EPOCHS = 20\n",
        "\n",
        "plt.style.use(\"ggplot\")\n",
        "plt.figure()\n",
        "plt.plot(np.arange(0, NUM_EPOCHS), H.history[\"loss\"], label=\"train_loss\")\n",
        "plt.plot(np.arange(0, NUM_EPOCHS), H.history[\"val_loss\"], label=\"val_loss\")\n",
        "plt.plot(np.arange(0, NUM_EPOCHS), H.history[\"acc\"], label=\"train_acc\")\n",
        "plt.plot(np.arange(0, NUM_EPOCHS), H.history[\"val_acc\"], label=\"val_acc\")\n",
        "plt.title(\"Training Loss and Accuracy\")\n",
        "plt.xlabel(\"Epoch #\")\n",
        "plt.ylabel(\"Loss/Accuracy\")\n",
        "plt.legend()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "X_test, y_test = read_and_process_image(test_imgs[0:4]) \n",
        "x = np.array(X_test)\n",
        "test_datagen = ImageDataGenerator(rescale=1./255)\n",
        "\n",
        "# predict on first 4 images in the test set and plot the results\n",
        "i = 0\n",
        "text_labels = []\n",
        "plt.figure(figsize=(30,20))\n",
        "for batch in test_datagen.flow(x, batch_size=1):\n",
        "    pred = model.predict(batch)\n",
        "    if pred > 0.5:\n",
        "        text_labels.append('dog')\n",
        "    else:\n",
        "        text_labels.append('cat')\n",
        "    plt.subplot(5 / columns + 1, columns, i + 1)\n",
        "    plt.title(text_labels[i])\n",
        "    imgplot = plt.imshow(batch[0])\n",
        "    i += 1\n",
        "    if i % 10 == 0:\n",
        "        break\n",
        "plt.show()\n",
        "\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "W9oDVPFLYeP7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_vgg = models.Sequential()\n",
        "model_vgg.add(conv_base_vgg16)\n",
        "model_vgg.add(layers.Flatten())\n",
        "model_vgg.add(layers.Dense(256, activation='relu'))\n",
        "model_vgg.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "# model_vgg.summary()\n",
        "\n",
        "print('Number of trainable weights :', len(model.trainable_weights))\n",
        "conv_base_vgg16.trainable = False\n",
        "print('Number of trainable weights after freezing base:', len(model.trainable_weights))\n",
        "\n",
        "model_vgg.compile(loss='binary_crossentropy', optimizer=optimizers.RMSprop(lr=2e-5), metrics=['acc'])\n",
        "\n",
        "H_vgg = model_vgg.fit_generator(train_generator,\n",
        "                              steps_per_epoch=ntrain // batch_size,\n",
        "                              epochs=20,\n",
        "                              validation_data=val_generator,\n",
        "                              validation_steps=nval // batch_size)\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "import h5py\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "from glob import glob\n",
        "NUM_EPOCHS = 20\n",
        "\n",
        "plt.style.use(\"ggplot\")\n",
        "plt.figure()\n",
        "plt.plot(np.arange(0, NUM_EPOCHS), H_vgg.history[\"loss\"], label=\"train_loss\")\n",
        "plt.plot(np.arange(0, NUM_EPOCHS), H_vgg.history[\"val_loss\"], label=\"val_loss\")\n",
        "plt.plot(np.arange(0, NUM_EPOCHS), H_vgg.history[\"acc\"], label=\"train_acc\")\n",
        "plt.plot(np.arange(0, NUM_EPOCHS), H_vgg.history[\"val_acc\"], label=\"val_acc\")\n",
        "plt.title(\"Training Loss and Accuracy\")\n",
        "plt.xlabel(\"Epoch #\")\n",
        "plt.ylabel(\"Loss/Accuracy\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bAr9CkdcYx70",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_ResNet = models.Sequential()\n",
        "model_ResNet.add(conv_base_ResNet50)\n",
        "model_ResNet.add(layers.Flatten())\n",
        "model_ResNet.add(layers.Dense(256, activation='relu'))\n",
        "model_ResNet.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "# model_vgg.summary()\n",
        "\n",
        "print('Number of trainable weights :', len(model.trainable_weights))\n",
        "conv_base_ResNet50.trainable = False\n",
        "print('Number of trainable weights after freezing  base:', len(model.trainable_weights))\n",
        "\n",
        "model_ResNet.compile(loss='binary_crossentropy', optimizer=optimizers.RMSprop(lr=2e-5), metrics=['acc'])\n",
        "\n",
        "H_ResNet = model_ResNet.fit_generator(train_generator,\n",
        "                              steps_per_epoch=ntrain // batch_size,\n",
        "                              epochs=20,\n",
        "                              validation_data=val_generator,\n",
        "                              validation_steps=nval // batch_size)\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "import h5py\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "from glob import glob\n",
        "NUM_EPOCHS = 20\n",
        "\n",
        "plt.style.use(\"ggplot\")\n",
        "plt.figure()\n",
        "plt.plot(np.arange(0, NUM_EPOCHS), H_ResNet.history[\"loss\"], label=\"train_loss\")\n",
        "plt.plot(np.arange(0, NUM_EPOCHS), H_ResNet.history[\"val_loss\"], label=\"val_loss\")\n",
        "plt.plot(np.arange(0, NUM_EPOCHS), H_ResNet.history[\"acc\"], label=\"train_acc\")\n",
        "plt.plot(np.arange(0, NUM_EPOCHS), H_ResNet.history[\"val_acc\"], label=\"val_acc\")\n",
        "plt.title(\"Training Loss and Accuracy\")\n",
        "plt.xlabel(\"Epoch #\")\n",
        "plt.ylabel(\"Loss/Accuracy\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2tKVUW_yY2vs",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "model_InceptionV3 = models.Sequential()\n",
        "model_InceptionV3.add(conv_base_InceptionV3)\n",
        "model_InceptionV3.add(layers.Flatten())\n",
        "model_InceptionV3.add(layers.Dense(256, activation='relu'))\n",
        "model_InceptionV3.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "print('Number of trainable weights :', len(model.trainable_weights))\n",
        "conv_base_InceptionV3.trainable = False\n",
        "print('Number of trainable weights after freezing base:', len(model.trainable_weights))\n",
        "\n",
        "model_InceptionV3.compile(loss='binary_crossentropy', optimizer=optimizers.RMSprop(lr=2e-5), metrics=['acc'])\n",
        "\n",
        "H_IV3 = model_InceptionV3.fit_generator(train_generator,\n",
        "                              steps_per_epoch=ntrain // batch_size,\n",
        "                              epochs=20,\n",
        "                              validation_data=val_generator,\n",
        "                              validation_steps=nval // batch_size)\n",
        "\n",
        "\n",
        "import tensorflow as tf\n",
        "import h5py\n",
        "import matplotlib.pyplot as plt\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import cv2\n",
        "import os\n",
        "\n",
        "from glob import glob\n",
        "NUM_EPOCHS = 20\n",
        "\n",
        "plt.style.use(\"ggplot\")\n",
        "plt.figure()\n",
        "plt.plot(np.arange(0, NUM_EPOCHS), H_IV3.history[\"loss\"], label=\"train_loss\")\n",
        "plt.plot(np.arange(0, NUM_EPOCHS), H_IV3.history[\"val_loss\"], label=\"val_loss\")\n",
        "plt.plot(np.arange(0, NUM_EPOCHS), H_IV3.history[\"acc\"], label=\"train_acc\")\n",
        "plt.plot(np.arange(0, NUM_EPOCHS), H_IV3.history[\"val_acc\"], label=\"val_acc\")\n",
        "plt.title(\"Training Loss and Accuracy\")\n",
        "plt.xlabel(\"Epoch #\")\n",
        "plt.ylabel(\"Loss/Accuracy\")\n",
        "plt.legend()\n",
        "plt.show()"
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}